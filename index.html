<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- ===== Meta for social sharing ===== -->
  <meta name="description" content="REAR is a three-stage, LLM-free framework for effective multi-table retrieval that jointly optimizes query–table relevance and table–table joinability." />
  <meta property="og:title" content="REAR: Retrieve, Expand and Refine for Effective Multitable Retrieval" />
  <meta property="og:description" content="A three-stage retrieval framework that jointly optimizes query–table relevance and table–table joinability without online LLM calls." />
  <meta property="og:url" content="https://rear.github.io" />

  <meta name="twitter:title" content="REAR: Retrieve, Expand and Refine for Effective Multitable Retrieval" />
  <meta name="twitter:description" content="LLM-free multi-table retrieval framework achieving competitive performance with 92% fewer tokens." />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="keywords" content="REAR, table retrieval, multi-table, joinability, RAG, NLP, text-to-SQL" />

  <title>REAR: Retrieve, Expand and Refine</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <!-- Template CSS -->
  <link rel="stylesheet" href="../tabard/static/css/bulma.min.css" />
  <link rel="stylesheet" href="../tabard/static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="../tabard/static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="../tabard/static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="../tabard/static/css/index.css" />

  <!-- Template JS -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="../tabard/static/js/fontawesome.all.min.js"></script>
  <script src="../tabard/static/js/bulma-carousel.min.js"></script>
  <script src="../tabard/static/js/bulma-slider.min.js"></script>
  <script src="../tabard/static/js/index.js"></script>
</head>
<body>

  <!-- ===== Hero / Header ===== -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="font-variant: small-caps;">REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Rishita Agarwal</a>
                <img src="../tabard/images/authors/ASU-logo.png" alt="ASU" class="aff-logo">,
              </span>
              <span class="author-block">
                <a href="https://himanshu-skid19.github.io" target="_blank">Himanshu Singhal</a>
                <img src="../tabard/images/authors/ASU-logo.png" alt="ASU" class="aff-logo">,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Peter Baile Chen</a>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/manan-roy-choudhury-2b2093208/" target="_blank">Manan Roy Choudhury</a>
                <img src="../tabard/images/authors/ASU-logo.png" alt="ASU" class="aff-logo">,
              </span>
              <span class="author-block">
                <a href="#" target="_blank">Dan Roth</a>,
              </span>
              <span class="author-block">
                <a href="https://vgupta123.github.io/" target="_blank">Vivek Gupta</a>
                <img src="../tabard/images/authors/ASU-logo.png" alt="ASU" class="aff-logo">
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <img src="../tabard/images/authors/ASU-logo.png" alt="ASU" class="aff-logo"> Arizona State University,
              </span>
              <span class="author-block">
                University of Pennsylvania
              </span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top:1rem; border-top:1px solid #ddd; padding-top:0.5rem;">
              <span class="author-block" style="font-weight:600; color:#696969">
                arXiv 2025
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- Paper -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2511.00805" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Code -->
                <span class="link-block">
                  <a href="https://github.com/CoRAL-ASU/REaR" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>

              </div>
            </div>

            <!-- ===== Main Figure ===== -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-14 has-text-centered">
          <figure class="image" style="max-width:100%; margin: 0 auto;">
            <img src="figures/arch_diagram.png"
                 alt="REAR Framework Overview"
                 style="width:100%; border-radius:8px;" />
          </figure>
          <h2 class="subtitle has-text-centered" style="margin-top:1rem;">
            Overview of the REAR three-stage pipeline: (1) Retrieve query-aligned tables,
            (2) Expand with structurally joinable tables via FAISS column search,
            (3) Refine by jointly scoring relevance and joinability.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- ===== Abstract ===== -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">About</h2>
          <div class="content has-text-justified">
            <p>
              Answering natural language queries over relational data often requires retrieving and reasoning over multiple tables, yet most retrievers optimize only for query–table relevance and ignore table–table compatibility. We introduce REAR (Retrieve, Expand and Refine), a three-stage, LLM-free framework that separates semantic relevance from structural joinability for efficient, high-fidelity multi-table retrieval. REAR (i) retrieves query-aligned tables, (ii) expands these with structurally joinable tables via fast, precomputed column-embedding comparisons, and (iii) refines them by pruning noisy or weakly related candidates. REAR achieves performance competitive with state-of-the-art LLM-augmented systems while reducing token usage by 92.24% compared to ARM.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- ===== Dataset / Benchmarks Section ===== -->
<section class="section" id="dataset">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Datasets</h2>

    <!-- Overview -->
    <div class="content has-text-justified">
      <h3 class="title is-4">Evaluation Benchmarks</h3>
      <p>
        We evaluate REAR on three established multi-table benchmarks: <strong>BIRD</strong>,
        <strong>Spider</strong>, and <strong>MMQA</strong>. Each benchmark tests a different facet
        of multi-table retrieval — from schema-rich enterprise databases to open-domain tables.
        All benchmarks require identifying the correct set of tables to answer a natural language query,
        making them well-suited for measuring both recall and precision of multi-table retrieval systems.
      </p>
    </div>

    <!-- Dataset Statistics -->
    <div class="content has-text-justified" style="margin-top:2rem;">
      <h3 class="title is-4">Statistics</h3>
      <p>
        The benchmarks span a diverse range of database sizes, table counts, and query complexities.
        On average, each query requires 1.91–2.22 tables, making joint retrieval essential.
        Below are summary statistics for each benchmark.
      </p>

      <div class="columns is-centered" style="margin-top:1.5rem;">
        <div class="column is-6 has-text-centered">
          <div class="box">
            <p class="title is-5">BIRD &amp; Spider</p>
            <table class="table is-fullwidth is-bordered is-striped is-narrow" style="font-size:0.9rem;">
              <thead><tr><th>Dataset</th><th>DBs</th><th>Tables</th><th>Queries</th><th>Avg. Tables/Q</th></tr></thead>
              <tbody>
                <tr><td>BIRD</td><td>11</td><td>75</td><td>1,534</td><td>1.96</td></tr>
                <tr><td>Spider</td><td>20</td><td>139</td><td>1,034</td><td>1.91</td></tr>
              </tbody>
            </table>
          </div>
          <p class="is-size-6 has-text-grey">Table 1: BIRD and Spider statistics.</p>
        </div>
        <div class="column is-6 has-text-centered">
          <div class="box">
            <p class="title is-5">MMQA</p>
            <table class="table is-fullwidth is-bordered is-striped is-narrow" style="font-size:0.9rem;">
              <thead><tr><th>Dataset</th><th>DBs</th><th>Tables</th><th>Queries</th><th>Avg. Tables/Q</th></tr></thead>
              <tbody>
                <tr><td>MMQA</td><td>—</td><td>695</td><td>3,312</td><td>2.22</td></tr>
              </tbody>
            </table>
            <br/>
            <p class="has-text-justified is-size-6">
              MMQA is an open-domain multi-table QA dataset with 695 heterogeneous tables requiring
              multi-hop reasoning across tables with no fixed database schema.
            </p>
          </div>
          <p class="is-size-6 has-text-grey">Table 2: MMQA statistics.</p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- ===== Methodology Section ===== -->
<section class="section" id="modeling-approaches">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Methodology</h2>

    <section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
          <figure class="image" style="max-width:100%; margin: 0 auto;">
            <img src="figures/arch_diagram.png"
                 alt="REAR Framework Architecture"
                 style="width:100%; border-radius:8px;" />
          </figure>
          <h2 class="subtitle has-text-centered" style="margin-top:1rem;">
            Detailed view of the REAR framework: Retrieve, Expand, and Refine stages.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

    <div class="content has-text-justified">
      <p>
        REAR comprises three cleanly separated stages, each targeting a distinct aspect of multi-table retrieval:
      </p>
      <ul>
        <li>
          <strong>Stage 1 — Retrieve:</strong> Select top-<em>k</em> relevant tables using standard dense, sparse,
          or hybrid retrievers (BM25, SPLADE, UAE, GTE, e5-mistral, BGE) to ensure query-table relevance.
        </li>
        <li>
          <strong>Stage 2 — Expand:</strong> Augment the base set with structurally joinable tables by measuring
          column embedding similarity via FAISS approximate nearest neighbor search, followed by cross-encoder
          reranking to filter semantically distant candidates.
        </li>
        <li>
          <strong>Stage 3 — Refine:</strong> Score all candidates by jointly weighting query-table relevance
          (cross-encoder similarity) and table-table joinability (attention-weighted column-level scores),
          then rerank to the final top-<em>k</em> tables.
        </li>
      </ul>
      <p>
        Together, these stages achieve retrieval quality competitive with LLM-based systems at a fraction
        of the token cost, with no online LLM calls required at inference time.
      </p>
    </div>
  </div>
</section>


<!-- ===== Results Section ===== -->
<section class="hero is-small" id="results">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-2 has-text-centered">Results</h2>

      <!-- Brief summary -->
      <div class="content has-text-justified" style="margin-bottom:1.25rem;">
        <p>
          REAR consistently improves retrieval metrics across all datasets and retriever types.
          Table&nbsp;3 shows stage-by-stage results with the UAE dense retriever across BIRD, MMQA, and Spider.
          Table&nbsp;4 compares REAR against LLM-augmented baselines (ARM, JAR, MURRE), demonstrating
          competitive Full Recall and superior SQL execution accuracy at 92% fewer tokens.
        </p>
      </div>

      <!-- Results carousel -->
      <div id="results-carousel" class="carousel results-carousel">

        <!-- Table 3: Stage-by-stage retrieval results -->
        <div class="item" style="height:700px; display:flex; flex-direction:column; justify-content:center; padding: 2rem;">
          <div style="overflow-x:auto; max-width:100%;">
            <table class="table is-bordered is-striped is-narrow is-fullwidth" style="font-size:0.85rem; margin:0 auto;">
              <thead>
                <tr style="background:#f5f5f5;">
                  <th style="text-align:center;">Dataset</th>
                  <th style="text-align:center;">Method</th>
                  <th style="text-align:center;">Recall</th>
                  <th style="text-align:center;">Precision</th>
                  <th style="text-align:center;">Full Recall</th>
                </tr>
              </thead>
              <tbody>
                <tr><td rowspan="3" style="vertical-align:middle; text-align:center;"><strong>BIRD</strong></td>
                    <td>Retrieval (Top 5)</td><td style="text-align:center;">90.68</td><td style="text-align:center;">36.09</td><td style="text-align:center;">82.79</td></tr>
                <tr><td>+Expansion</td><td style="text-align:center;">96.81</td><td style="text-align:center;">25.26</td><td style="text-align:center;">93.42</td></tr>
                <tr style="background:#ebf5fb;"><td><strong>REAR (Full)</strong></td><td style="text-align:center;"><strong>93.96</strong></td><td style="text-align:center;"><strong>36.33</strong></td><td style="text-align:center;"><strong>87.29</strong></td></tr>
                <tr><td rowspan="3" style="vertical-align:middle; text-align:center;"><strong>MMQA</strong></td>
                    <td>Retrieval (Top 5)</td><td style="text-align:center;">73.92</td><td style="text-align:center;">32.61</td><td style="text-align:center;">52.27</td></tr>
                <tr><td>+Expansion</td><td style="text-align:center;">87.91</td><td style="text-align:center;">24.44</td><td style="text-align:center;">75.64</td></tr>
                <tr style="background:#ebf5fb;"><td><strong>REAR (Full)</strong></td><td style="text-align:center;"><strong>83.19</strong></td><td style="text-align:center;"><strong>36.86</strong></td><td style="text-align:center;"><strong>66.61</strong></td></tr>
                <tr><td rowspan="3" style="vertical-align:middle; text-align:center;"><strong>Spider</strong></td>
                    <td>Retrieval (Top 5)</td><td style="text-align:center;">98.06</td><td style="text-align:center;">29.75</td><td style="text-align:center;">96.61</td></tr>
                <tr><td>+Expansion</td><td style="text-align:center;">99.32</td><td style="text-align:center;">18.88</td><td style="text-align:center;">99.13</td></tr>
                <tr style="background:#ebf5fb;"><td><strong>REAR (Full)</strong></td><td style="text-align:center;"><strong>98.50</strong></td><td style="text-align:center;"><strong>29.61</strong></td><td style="text-align:center;"><strong>97.68</strong></td></tr>
              </tbody>
            </table>
          </div>
          <h2 class="subtitle has-text-centered" style="margin-top:1rem; font-size:0.95rem;">
            Table 3: Stage-by-stage Recall, Precision, and Full Recall across BIRD, MMQA, and Spider using the UAE dense retriever.
          </h2>
        </div>

        <!-- Table 4: Comparison with LLM-based methods -->
        <div class="item" style="height:700px; display:flex; flex-direction:column; justify-content:center; padding: 2rem;">
          <div style="overflow-x:auto; max-width:100%;">
            <table class="table is-bordered is-striped is-narrow" style="font-size:0.85rem; margin:0 auto; width:80%;">
              <thead>
                <tr style="background:#f5f5f5;">
                  <th style="text-align:center;">Method</th>
                  <th style="text-align:center;">BIRD Full Recall</th>
                  <th style="text-align:center;">BIRD SQL Acc (Gemini)</th>
                  <th style="text-align:center;">Tokens Used</th>
                </tr>
              </thead>
              <tbody>
                <tr><td>ARM</td><td style="text-align:center;">92.7</td><td style="text-align:center;">30.4</td><td style="text-align:center;">19,748</td></tr>
                <tr><td>JAR</td><td style="text-align:center;">77.9</td><td style="text-align:center;">29.1</td><td style="text-align:center;">2,222</td></tr>
                <tr><td>MURRE</td><td style="text-align:center;">80.1</td><td style="text-align:center;">—</td><td style="text-align:center;">17,655</td></tr>
                <tr style="background:#ebf5fb;"><td><strong>REAR (ours)</strong></td><td style="text-align:center;"><strong>87.3</strong></td><td style="text-align:center;"><strong>34.0</strong></td><td style="text-align:center;"><strong>1,534</strong></td></tr>
              </tbody>
            </table>
          </div>
          <h2 class="subtitle has-text-centered" style="margin-top:1rem; font-size:0.95rem;">
            Table 4: Comparison with LLM-augmented retrieval systems on BIRD. REAR achieves competitive Full Recall and the best SQL accuracy at 92% fewer tokens than ARM.
          </h2>
        </div>

      </div>
    </div>
  </div>
</section>


  <!-- ===== Team Section ===== -->
<section class="section" id="team">
  <div class="container is-max-desktop">
    <h2 class="title is-2 has-text-centered">Team</h2>

    <div class="team-row">
      <div class="team-member">
        <a href="#" target="_blank">
          <img src="images/authors/rishita.png" alt="Rishita Agarwal">
          Rishita Agarwal
        </a>
      </div>

      <div class="team-member">
        <a href="https://himanshu-skid19.github.io" target="_blank">
          <img src="images/authors/himanshu.png" alt="Himanshu Singhal">
          Himanshu Singhal
        </a>
      </div>

      <div class="team-member">
        <a href="#" target="_blank">
          <img src="images/authors/peter.png" alt="Peter Baile Chen">
          Peter Baile Chen
        </a>
      </div>

      <div class="team-member">
        <a href="https://www.linkedin.com/in/manan-roy-choudhury-2b2093208/" target="_blank">
          <img src="../tabard/images/authors/manan_choudhury.png" alt="Manan Roy Choudhury">
          Manan Roy <br> Choudhury
        </a>
      </div>

      <div class="team-member">
        <a href="#" target="_blank">
          <img src="images/authors/dan.png" alt="Dan Roth">
          Dan Roth
        </a>
      </div>

      <div class="team-member">
        <a href="https://vgupta123.github.io/" target="_blank">
          <img src="../tabard/images/authors/Vivek_gupta.png" alt="Vivek Gupta">
          Vivek Gupta
        </a>
      </div>
    </div>
  </div>
</section>


  <!-- ===== BibTeX ===== -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <h4>Please cite our paper as below if you use REAR in your research.</h4>
      <pre><code>@misc{agarwal2025rearretrieveexpandrefine,
      title={REaR: Retrieve, Expand and Refine for Effective Multitable Retrieval},
      author={Rishita Agarwal and Himanshu Singhal and Peter Baile Chen and Manan Roy Choudhury and Dan Roth and Vivek Gupta},
      year={2025},
      eprint={2511.00805},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2511.00805},
}</code></pre>
    </div>
  </section>


  <!-- ===== Footer ===== -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. You are free to borrow the source code of this website; please link back to this page in the footer. This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>
</html>
